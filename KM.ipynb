{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.98\n",
      "Decision Tree Accuracy: 1.00\n",
      "Random Forest Accuracy: 1.00\n",
      "Scaler and Random Forest model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('CP.csv')\n",
    "\n",
    "# Encode the categorical variable 'STATE'\n",
    "label_encoder = LabelEncoder()\n",
    "data['STATE'] = label_encoder.fit_transform(data['STATE'])\n",
    "\n",
    "# Ensure that only the relevant columns are used (including new fields)\n",
    "data = data[['Nitrogen', 'Phosphorus', 'Potassium', 'Temperature', 'Humidity', 'Rainfall', 'STATE', 'Crop']]\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data[['Nitrogen', 'Phosphorus', 'Potassium', 'Temperature', 'Humidity', 'Rainfall', 'STATE']]\n",
    "y = data['Crop']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the models\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "dtree = DecisionTreeClassifier()\n",
    "rforest = RandomForestClassifier()\n",
    "\n",
    "# Train the models\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "dtree.fit(X_train_scaled, y_train)\n",
    "rforest.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions using scaled test data\n",
    "logreg_pred = logreg.predict(X_test_scaled)\n",
    "dtree_pred = dtree.predict(X_test_scaled)\n",
    "rforest_pred = rforest.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy for each model\n",
    "logreg_acc = accuracy_score(y_test, logreg_pred)\n",
    "dtree_acc = accuracy_score(y_test, dtree_pred)\n",
    "rforest_acc = accuracy_score(y_test, rforest_pred)\n",
    "\n",
    "# Print accuracies\n",
    "print(f'Logistic Regression Accuracy: {logreg_acc:.2f}')\n",
    "print(f'Decision Tree Accuracy: {dtree_acc:.2f}')\n",
    "print(f'Random Forest Accuracy: {rforest_acc:.2f}')\n",
    "\n",
    "# Save the scaler and Random Forest model as pickle files\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "with open('rforest_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rforest, f)\n",
    "\n",
    "print(\"Scaler and Random Forest model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique States: ['Andaman and Nicobar' 'Andhra Pradesh' 'Assam' 'Chattisgarh' 'Goa'\n",
      " 'Gujarat' 'Haryana' 'Himachal Pradesh' 'Jammu and Kashmir' 'Karnataka'\n",
      " 'Kerala' 'Madhya Pradesh' 'Maharashtra' 'Manipur' 'Meghalaya' 'Nagaland'\n",
      " 'Odisha' 'Pondicherry' 'Punjab' 'Rajasthan' 'Tamil Nadu' 'Telangana'\n",
      " 'Tripura' 'Uttar Pradesh' 'Uttrakhand' 'West Bengal']\n",
      "Unique Crops: ['Rice' 'Maize' 'ChickPea' 'KidneyBeans' 'PigeonPeas' 'MothBeans'\n",
      " 'MungBean' 'Blackgram' 'Lentil' 'Pomegranate' 'Banana' 'Mango' 'Grapes'\n",
      " 'Watermelon' 'Muskmelon' 'Apple' 'Orange' 'Papaya' 'Coconut' 'Cotton'\n",
      " 'Jute' 'Coffee']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('CP.csv')\n",
    "\n",
    "# Get unique states (as original strings)\n",
    "unique_states = data['STATE'].unique()\n",
    "print(\"Unique States:\", unique_states)\n",
    "\n",
    "# Get unique crops (as original strings)\n",
    "unique_crops = data['Crop'].unique()\n",
    "print(\"Unique Crops:\", unique_crops)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
